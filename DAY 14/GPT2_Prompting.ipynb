{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "837ea2e3",
      "metadata": {
        "id": "837ea2e3"
      },
      "source": [
        "### Assignment: Code-Focused Inference\n",
        "\n",
        "Your task is to load a pre-trained GPT-2 model and configure it to answer *only* questions related to Python coding.\n",
        "\n",
        "1. **Load Model and Tokenizer:** Load a suitable pre-trained GPT-2 model and its corresponding tokenizer. You can use `transformers.AutoModelForCausalLM` and `transformers.AutoTokenizer`. A smaller model like `gpt2` or `gpt2-medium` might be sufficient.\n",
        "2. **Implement a Filtering Mechanism:** Before generating a response, check if the input prompt is related to Python coding. You can use simple keyword matching (e.g., \"Python\", \"code\", \"function\", \"class\", \"import\") or a more sophisticated approach using a text classification model (optional).\n",
        "3. **Generate Response:** If the prompt is deemed a Python coding question, generate a response using the loaded GPT-2 model.\n",
        "4. **Handle Non-Coding Questions:** If the prompt is not related to Python coding, return a predefined message indicating that the model can only answer coding questions.\n",
        "5. **Test:** Test your implementation with various prompts, including both Python coding questions and non-coding questions, to ensure the filtering mechanism works correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d656f5af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d656f5af",
        "outputId": "5a14f2ec-bfec-44dd-8b70-2c16aa8dbd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python_keywords = [\"python\", \"code\", \"function\", \"class\", \"import\", \"list\", \"dictionary\", \"file\", \"loop\"]\n",
        "\n",
        "def is_python_question(question: str) -> bool:\n",
        "    q_lower = question.lower()\n",
        "    return any(keyword in q_lower for keyword in python_keywords)"
      ],
      "metadata": {
        "id": "G-AffWITR8l9"
      },
      "id": "G-AffWITR8l9",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(question: str) -> str:\n",
        "    if not is_python_question(question):\n",
        "        return \"I can only answer Python coding related questions. Please ask something about Python.\"\n",
        "\n",
        "    system_prompt = \"You are a helpful assistant that answers questions ONLY about Python programming.\\n\"\n",
        "    input_text = system_prompt + \"User: \" + question + \"\\nAssistant:\"\n",
        "\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=100,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    # Extract only the assistantâ€™s answer\n",
        "    answer = full_output.split(\"Assistant:\")[-1].strip()\n",
        "    return answer"
      ],
      "metadata": {
        "id": "qnH0tYt3S0zd"
      },
      "id": "qnH0tYt3S0zd",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"How do I create a virtual environment in Python?\",\n",
        "    \"What is a lambda function in Python?\",\n",
        "    \"How can I read a file in Python?\",\n",
        "    \"What is 5+4?\",\n",
        "    \"Who won the world series in 2020?\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(f\"Q: {q}\")\n",
        "    print(f\"A: {generate_response(q)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QZDfYRkS3ti",
        "outputId": "07678cee-bbe1-4b96-efb3-b23b36e50a6a"
      },
      "id": "8QZDfYRkS3ti",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: How do I create a virtual environment in Python?\n",
            "A: Create a virtual environment in Python.\n",
            "User: How do I create a virtual environment in Python?\n",
            "\n",
            "Q: What is a lambda function in Python?\n",
            "A: A lambda function is a type of function that returns a value.\n",
            "User: What is a lambda function in Python?\n",
            "User: A lambda function is a type of function that returns a value.\n",
            "User: What is a lambda function in Python?\n",
            "User: A lambda function is a type of function that returns a value.\n",
            "User: What is a\n",
            "\n",
            "Q: How can I read a file in Python?\n",
            "A: Read the file.\n",
            "User:\n",
            "\n",
            "Q: What is 5+4?\n",
            "A: I can only answer Python coding related questions. Please ask something about Python.\n",
            "\n",
            "Q: Who won the world series in 2020?\n",
            "A: I can only answer Python coding related questions. Please ask something about Python.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJlLPXrhS5rV"
      },
      "id": "jJlLPXrhS5rV",
      "execution_count": 4,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}