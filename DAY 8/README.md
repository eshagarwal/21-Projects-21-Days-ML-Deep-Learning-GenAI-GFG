# CIFAR-100 Image Classification ğŸ–¼ï¸

## Project Overview

**Objective:** Build a deep CNN model to classify 32x32 color images from the CIFAR-100 dataset into 100 different classes.

CIFAR-100 contains 60,000 images (50,000 training + 10,000 testing) across 100 classes with 600 images per class, making it significantly more challenging than standard datasets.

## ğŸ¯ Key Features

- **Deep CNN Architecture:** Progressive filter increase (32â†’64â†’128â†’256)
- **Advanced Regularization:** Batch normalization, dropout, and weight decay
- **Optimized Training:** Early stopping, model checkpointing, and learning rate scheduling
- **Comprehensive Evaluation:** F1-score, accuracy, confusion matrix analysis

## ğŸ“Š Dataset

- **Source:** CIFAR-100 (Keras built-in dataset)
- **Images:** 32x32 RGB color images
- **Classes:** 100 fine-grained categories
- **Split:** 50,000 training / 10,000 testing

## ğŸ—ï¸ Model Architecture

```
Input (32, 32, 3)
â”œâ”€â”€ Conv2D(32) + BatchNorm + Conv2D(32) + MaxPool + Dropout(0.25)
â”œâ”€â”€ Conv2D(64) + BatchNorm + Conv2D(64) + Dropout(0.25)
â”œâ”€â”€ Conv2D(128) + BatchNorm + Conv2D(128) + Dropout(0.25)
â”œâ”€â”€ Conv2D(256) + BatchNorm + Conv2D(256) + Dropout(0.25)
â”œâ”€â”€ Flatten
â”œâ”€â”€ Dense(512) + BatchNorm + Dropout(0.5)
â”œâ”€â”€ Dense(256) + BatchNorm + Dropout(0.5)
â””â”€â”€ Dense(100, softmax)
```

## ğŸ”§ Technologies

- **Framework:** TensorFlow/Keras
- **Libraries:** NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn
- **Optimization:** AdamW optimizer with weight decay

## ğŸ“ˆ Training Strategy

- **Optimizer:** AdamW (lr=0.001, weight_decay=0.0001)
- **Callbacks:** Early stopping, model checkpoint, learning rate reduction
- **Monitoring:** Validation F1-score for best model selection
- **Batch Size:** 32, Validation Split: 10%

## ğŸ† Results

The deep CNN model achieved competitive performance on this challenging 100-class classification task:

- **Architecture Effectiveness:** Progressive feature learning with proper regularization
- **Training Stability:** Successful convergence with early stopping and LR scheduling
- **Generalization:** Good performance across diverse image categories

---
**Day 8** | GeeksForGeeks 21 Projects Challenge | Intro to Deep Learning 


